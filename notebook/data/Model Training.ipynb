{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import Data and required Packages\n",
    "#### importing Pandas ,Numpy ,Matplotlib,Seaborn,and Warnings Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboostNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/75/dd/9afe0d9d0f61a5384c3932626a022e38c396a5d88e6f5345ad2f7b576747/xgboost-1.7.6-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-1.7.6-py3-none-win_amd64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy in e:\\machine learning\\mlproject1\\venv\\lib\\site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in e:\\machine learning\\mlproject1\\venv\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Using cached xgboost-1.7.6-py3-none-win_amd64.whl (70.9 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.6\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/5f/08/c66e99f06fb73f727c870172f0962c103262ac68839cc05234709b7b45c2/scikit_learn-1.3.0-cp38-cp38-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.0-cp38-cp38-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in e:\\machine learning\\mlproject1\\venv\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in e:\\machine learning\\mlproject1\\venv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\s k e f\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn) (1.3.1)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.0-cp38-cp38-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.2 MB 653.6 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.2/9.2 MB 2.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.5/9.2 MB 3.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.2/9.2 MB 6.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.2/9.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.0/9.2 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.8/9.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.8/9.2 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.8/9.2 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.8/9.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.9/9.2 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.0/9.2 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.0/9.2 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.2/9.2 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.6/9.2 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.8/9.2 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.9/9.2 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.1/9.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.8/9.2 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.5/9.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.7/9.2 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.7/9.2 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.3/9.2 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.8/9.2 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.0 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## Modelling\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the csv data as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('stud.csv')\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['math_score'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Categories in 'gender' variable:     \",end=\" \" )\n",
    "print(df['gender'].unique())\n",
    "\n",
    "print(\"Categories in 'race_ethnicity' variable:  \",end=\" \")\n",
    "print(df['race_ethnicity'].unique())\n",
    "\n",
    "print(\"Categories in'parental level of education' variable:\",end=\" \" )\n",
    "print(df['parental_level_of_education'].unique())\n",
    "\n",
    "print(\"Categories in 'lunch' variable:     \",end=\" \" )\n",
    "print(df['lunch'].unique())\n",
    "\n",
    "print(\"Categories in 'test preparation course' variable:     \",end=\" \" )\n",
    "print(df['test_preparation_course'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['math_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer with 3 types of transformers \n",
    "num_features=X.select_dtypes(exclude='object').columns\n",
    "cat_features=X.select_dtypes(include='object').columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor=ColumnTransformer(\n",
    "    [  (\"oneHotEncoder\",oh_transformer,cat_features),\n",
    "     (\"StandardScaler\",numeric_transformer,num_features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seperate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "### randomstate is o ensure that the same random split is reproducible if you need to perform the same operation again.\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Evaluate function to give all metrics after model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true,predicted):\n",
    "    mae=mean_absolute_error(true,predicted)\n",
    "    mse=mean_squared_error(true,predicted)\n",
    "    rmse=np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square=r2_score(true,predicted)\n",
    "    return mae ,rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    \"Linear Rergression\": LinearRegression(),\n",
    "    \"Lasso\":Lasso(),\n",
    "    \"Ridge\":Ridge(),\n",
    "    \"K_Neighbours Regressor\":KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\":RandomForestRegressor(),\n",
    "    \"XGBRegressor\":XGBRegressor(),\n",
    "    \"CatBoosting Regressor\":CatBoostRegressor(verbose=False),\n",
    "    \"Adaboost Regreesor\":AdaBoostRegressor()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=[]\n",
    "r2_list=[]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,Y_train)##Model training\n",
    "    \n",
    "    Y_train_pred=model.predict(X_train)\n",
    "    Y_test_pred=model.predict(X_test)\n",
    "      \n",
    "        \n",
    "    ## Evaluate Train and Test dataset\n",
    "    model_train_mae,model_train_rmse,model_train_r2=evaluate_model(Y_train,Y_train_pred)\n",
    "    \n",
    "    model_test_mae,model_test_rmse,model_test_r2=evaluate_model(Y_test,Y_test_pred)\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print(\"Model performance for training set\")\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error:{:.4f}\".format( model_train_mae))\n",
    "    print(\"- R2 Score:{:.4f}\".format(model_train_r2))\n",
    "    \n",
    "    print(\"-\"*35)\n",
    "    \n",
    "    print(\"Model performance for Test set\")\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error:{:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score:{:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(model_list,r2_list)),columns=[\"Model\",\"r2 Score\"]).sort_values(by=\"r2 Score\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model=LinearRegression(fit_intercept=True)\n",
    "lin_model=lin_model.fit(X_train,Y_train)\n",
    "Y_pred=lin_model.predict(X_test)\n",
    "score=r2_score(Y_test,Y_pred)*100\n",
    "print(\"Accuracy of the model is %.2f\" %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot y_pred and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test,Y_pred);\n",
    "plt.xlabel(\"Actual\");\n",
    "plt.ylabel(\"Predicted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=Y_test,y=Y_pred,ci=None,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame({'Actual Value':Y_test,'Predicted Value':Y_pred,\"Difference\":Y_test-Y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
